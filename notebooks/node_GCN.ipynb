{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tnrange\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import diags\n",
    "from scipy.sparse import eye\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8368/2440406101.py:1: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  paper_features_label = np.genfromtxt(path/'cora.content', dtype=np.str)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "data/cora/cora.content not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m paper_features_label \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mgenfromtxt(path\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcora.content\u001b[39;49m\u001b[39m'\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mstr)\n\u001b[1;32m      2\u001b[0m paper_features_label\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:1939\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[1;32m   1937\u001b[0m     fname \u001b[39m=\u001b[39m os_fspath(fname)\n\u001b[1;32m   1938\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m):\n\u001b[0;32m-> 1939\u001b[0m     fid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49m_datasource\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[1;32m   1940\u001b[0m     fid_ctx \u001b[39m=\u001b[39m contextlib\u001b[39m.\u001b[39mclosing(fid)\n\u001b[1;32m   1941\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: data/cora/cora.content not found."
     ]
    }
   ],
   "source": [
    "paper_features_label = np.genfromtxt(path/'cora.content', dtype=np.str)\n",
    "paper_features_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 4, 4, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = csr_matrix(paper_features_label[:, 1:-1], dtype=np.float32)\n",
    "labels = paper_features_label[:, -1]\n",
    "lbl2idx = {k:v for v,k in enumerate(sorted(np.unique(labels)))}\n",
    "labels = [lbl2idx[e] for e in labels]\n",
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  31336, 1061127, 1106406, ..., 1128978,  117328,   24043],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = paper_features_label[:,0].astype(np.int32)\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 163,  402],\n",
       "       [ 163,  659],\n",
       "       [ 163, 1696],\n",
       "       ...,\n",
       "       [1887, 2258],\n",
       "       [1902, 1887],\n",
       "       [ 837, 1686]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper2idx = {k:v for v,k in enumerate(papers)}\n",
    "edges = np.genfromtxt(path/'cora.cites', dtype=np.int32)\n",
    "edges = np.asarray([paper2idx[e] for e in edges.flatten()], np.int32).reshape(edges.shape)\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                 shape=(len(labels), len(labels)), dtype=np.float32)\n",
    "\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = (rowsum ** -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = normalize(adj + eye(adj.shape[0])) #Normalizing for removing gradient vanishing and exploding problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = torch.FloatTensor(adj.todense())\n",
    "features = torch.FloatTensor(features.todense())\n",
    "labels = torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(34)\n",
    "n_train = 200\n",
    "n_val = 300\n",
    "n_test = len(features) - n_train - n_val\n",
    "idxs = np.random.permutation(len(features))\n",
    "idx_train = torch.LongTensor(idxs[:n_train])\n",
    "idx_val   = torch.LongTensor(idxs[n_train:n_train+n_val])\n",
    "idx_test  = torch.LongTensor(idxs[n_train+n_val:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = adj.to(device)\n",
    "features = features.to(device)\n",
    "labels = labels.to(device)\n",
    "idx_train = idx_train.to(device)\n",
    "idx_val = idx_val.to(device)\n",
    "idx_test = idx_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ') '\n",
    "    \n",
    "    \n",
    "    \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1433)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_labels = labels.max().item() + 1\n",
    "n_features = features.shape[1]\n",
    "n_labels, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(34)\n",
    "\n",
    "model = GCN(nfeat=n_features,\n",
    "            nhid=20, #hidden = 16\n",
    "            nclass=n_labels,\n",
    "            dropout=0.5) #dropout = 0.5\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "def step():\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj)\n",
    "    loss = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "    acc = accuracy(output[idx_train], labels[idx_train])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item(), acc\n",
    "\n",
    "def evaluate(idx):\n",
    "    model.eval()\n",
    "    output = model(features, adj)\n",
    "    loss = F.nll_loss(output[idx], labels[idx])\n",
    "    acc = accuracy(output[idx], labels[idx])\n",
    "    \n",
    "    return loss.item(), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ab01bda833427fb4e8574a6a2213ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0, Train Loss: 1.984, Train Acc: 0.095, Validation Loss: 1.937, Validation Acc: 0.063\n",
      "Epochs: 99, Train Loss: 1.838, Train Acc: 0.245, Validation Loss: 1.824, Validation Acc: 0.320\n",
      "Epochs: 199, Train Loss: 1.699, Train Acc: 0.365, Validation Loss: 1.731, Validation Acc: 0.397\n",
      "Epochs: 299, Train Loss: 1.515, Train Acc: 0.695, Validation Loss: 1.603, Validation Acc: 0.597\n",
      "Epochs: 399, Train Loss: 1.280, Train Acc: 0.760, Validation Loss: 1.430, Validation Acc: 0.640\n",
      "Epochs: 499, Train Loss: 1.059, Train Acc: 0.810, Validation Loss: 1.260, Validation Acc: 0.680\n",
      "Epochs: 599, Train Loss: 0.886, Train Acc: 0.865, Validation Loss: 1.127, Validation Acc: 0.723\n",
      "Epochs: 699, Train Loss: 0.754, Train Acc: 0.920, Validation Loss: 1.023, Validation Acc: 0.780\n",
      "Epochs: 799, Train Loss: 0.652, Train Acc: 0.955, Validation Loss: 0.945, Validation Acc: 0.803\n",
      "Epochs: 899, Train Loss: 0.570, Train Acc: 0.960, Validation Loss: 0.884, Validation Acc: 0.823\n",
      "Epochs: 999, Train Loss: 0.502, Train Acc: 0.960, Validation Loss: 0.835, Validation Acc: 0.823\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "print_steps = 100\n",
    "train_loss, train_acc = [], []\n",
    "val_loss, val_acc = [], []\n",
    "\n",
    "for i in tnrange(epochs):\n",
    "    tl, ta = step()\n",
    "    train_loss += [tl]\n",
    "    train_acc += [ta]\n",
    "    \n",
    "    if((i+1)%print_steps) == 0 or i == 0:\n",
    "        tl, ta = evaluate(idx_train)\n",
    "        vl, va = evaluate(idx_val)\n",
    "        val_loss += [vl]\n",
    "        val_acc += [va]\n",
    "        \n",
    "        print('Epochs: {}, Train Loss: {:.3f}, Train Acc: {:.3f}, Validation Loss: {:.3f}, Validation Acc: {:.3f}'.format(i, tl, ta, vl, va))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "# moved to cpu\n",
    "# train_acc = [i.cpu() for i in train_acc]\n",
    "# val_acc = [i.cpu() for i in val_acc]\n",
    "\n",
    "# train_loss = np.array(train_loss)\n",
    "# train_acc = np.array(train_acc)\n",
    "# val_loss = np.array(val_loss)\n",
    "# val_acc = np.array(val_acc) \n",
    "\n",
    "# axes[0].plot(train_loss, label='train')\n",
    "# axes[0].plot(val_loss, label='validation')\n",
    "# axes[0].set_xlabel('Epochs')\n",
    "# axes[0].set_ylabel('Loss')\n",
    "# axes[0].legend()\n",
    "\n",
    "# axes[1].plot(train_acc, label='train')\n",
    "# axes[1].plot(val_acc, label='validation')\n",
    "# axes[1].set_xlabel('Epochs')\n",
    "# axes[1].set_ylabel('Accuracy')\n",
    "# axes[1].legend()\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# moved to cpu\n",
    "train_acc = [i.cpu() for i in train_acc]\n",
    "val_acc = [i.cpu() for i in val_acc]\n",
    "\n",
    "ax = axes[0]\n",
    "axes[0].plot(train_loss[::print_steps] + [train_loss[-1]], label='Train')\n",
    "axes[0].plot(val_loss, label='Validation')\n",
    "axes[1].plot(train_acc[::print_steps] + [train_acc[-1]], label='Train')\n",
    "axes[1].plot(val_acc, label='Validation')\n",
    "axes[0].grid()\n",
    "axes[1].grid()\n",
    "\n",
    "for ax, t in zip(axes, ['Loss','Accuracy']): \n",
    "    ax.legend(), ax.set_title(t, size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(features, adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rule_Learning</td>\n",
       "      <td>Rule_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Theory</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theory</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>Reinforcement_Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Theory</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "      <td>Genetic_Algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Theory</td>\n",
       "      <td>Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>Probabilistic_Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Neural_Networks</td>\n",
       "      <td>Neural_Networks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Real                    Pred\n",
       "0           Rule_Learning           Rule_Learning\n",
       "1                  Theory                  Theory\n",
       "2      Genetic_Algorithms      Genetic_Algorithms\n",
       "3                  Theory                  Theory\n",
       "4         Neural_Networks  Reinforcement_Learning\n",
       "5                  Theory                  Theory\n",
       "6         Neural_Networks   Probabilistic_Methods\n",
       "7         Neural_Networks         Neural_Networks\n",
       "8      Genetic_Algorithms      Genetic_Algorithms\n",
       "9   Probabilistic_Methods   Probabilistic_Methods\n",
       "10                 Theory                  Theory\n",
       "11        Neural_Networks   Probabilistic_Methods\n",
       "12        Neural_Networks         Neural_Networks"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = 13\n",
    "idx_sample = idx_test[torch.randperm(len(idx_test))[:samples]]\n",
    "\n",
    "idx2lbl = {v:k for k,v in lbl2idx.items()}\n",
    "df = pd.DataFrame({'Real': [idx2lbl[e] for e in labels[idx_sample].tolist()],\n",
    "                   'Pred': [idx2lbl[e] for e in output[idx_sample].argmax(1).tolist()]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
